<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Example of how to use series.system.estimation.masked.data package • series.system.estimation.masked.data</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Example of how to use series.system.estimation.masked.data package">
<meta property="og:description" content="series.system.estimation.masked.data">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">series.system.estimation.masked.data</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.0.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/example-use.html">Example of how to use series.system.estimation.masked.data package</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Example of how to use
series.system.estimation.masked.data package</h1>
            
      
      
      <div class="hidden name"><code>example-use.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The R package <code>series.system.estimation.masked.data</code> is a
framework for estimating the parameters of latent component lifetimes
from <em>masked data</em> in a series system.</p>
<p>Install the library with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">devtools</span><span class="fu">::</span><span class="fu"><a href="https://devtools.r-lib.org/reference/remote-reexports.html" class="external-link">install_github</a></span><span class="op">(</span><span class="st">"queelius/series_system_estimation_masked_data"</span><span class="op">)</span></code></pre></div>
<p>Once installed, you may load the library with:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">series.system.estimation.masked.data</span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/algebraic.mle" class="external-link">algebraic.mle</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://queelius.github.io/md.tools/" class="external-link">md.tools</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="masked-data">Masked data<a class="anchor" aria-label="anchor" href="#masked-data"></a>
</h2>
<p>Masked data is given by an i.i.d. sample of system lifetime data and
<em>plausible</em> candidate sets that contain the failed node.</p>
<p>The R package <code>series.system.estimation.masked.data</code>
contains several simulated masked data sets. For example, a series
system with <span class="math inline">\(10\)</span> exponentially
distributed component lifetimes is stored in
<code>exp_series_data_3</code>:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">exp_series_data_3</span>,drop_latent<span class="op">=</span><span class="cn">T</span>,pprint<span class="op">=</span><span class="cn">T</span><span class="op">)</span>
<span class="co">#&gt; <span style="color: #949494;"># A tibble: 100,000 × 23</span></span>
<span class="co">#&gt;          s     k     w    t.1    t.2    t.3     t.4    t.5    t.6     t.7</span>
<span class="co">#&gt;      <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 0.005<span style="text-decoration: underline;">24</span>     4     5 0.560  0.289  0.172  0.005<span style="text-decoration: underline;">24</span> 0.055<span style="text-decoration: underline;">7</span> 0.043<span style="text-decoration: underline;">7</span> 0.618  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 0.027<span style="text-decoration: underline;">7</span>      9     3 0.837  0.076<span style="text-decoration: underline;">9</span> 0.528  0.278   0.065<span style="text-decoration: underline;">9</span> 0.166  0.040<span style="text-decoration: underline;">5</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 0.048<span style="text-decoration: underline;">7</span>      7     3 0.278  0.136  0.546  0.180   0.089<span style="text-decoration: underline;">3</span> 0.348  0.048<span style="text-decoration: underline;">7</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 0.002<span style="text-decoration: underline;">23</span>     9     2 0.194  0.207  0.013<span style="text-decoration: underline;">2</span> 0.201   0.237  0.175  0.137  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 0.005<span style="text-decoration: underline;">21</span>     7     7 0.050<span style="text-decoration: underline;">0</span> 0.335  0.376  0.009<span style="text-decoration: underline;">58</span> 0.026<span style="text-decoration: underline;">3</span> 1.39   0.005<span style="text-decoration: underline;">21</span></span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 0.009<span style="text-decoration: underline;">13</span>     8     8 0.398  0.032<span style="text-decoration: underline;">7</span> 0.125  0.144   0.193  0.013<span style="text-decoration: underline;">5</span> 0.275  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 0.035<span style="text-decoration: underline;">6</span>      3     6 0.402  0.187  0.035<span style="text-decoration: underline;">6</span> 0.152   0.035<span style="text-decoration: underline;">6</span> 1.01   0.142  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 0.026<span style="text-decoration: underline;">4</span>      4     7 0.542  0.290  0.107  0.026<span style="text-decoration: underline;">4</span>  0.039<span style="text-decoration: underline;">2</span> 2.95   0.095<span style="text-decoration: underline;">2</span> </span>
<span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 0.015<span style="text-decoration: underline;">6</span>      4     5 1.44   0.137  0.024<span style="text-decoration: underline;">5</span> 0.015<span style="text-decoration: underline;">6</span>  0.115  0.301  0.112  </span>
<span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 0.007<span style="text-decoration: underline;">01</span>     9     7 0.145  0.260  0.396  0.114   0.647  0.388  0.182  </span>
<span class="co">#&gt; <span style="color: #949494;"># … with 99,990 more rows, and 13 more variables: t.8 &lt;dbl&gt;, t.9 &lt;dbl&gt;,</span></span>
<span class="co">#&gt; <span style="color: #949494;">#   t.10 &lt;dbl&gt;, c.1 &lt;lgl&gt;, c.2 &lt;lgl&gt;, c.3 &lt;lgl&gt;, c.4 &lt;lgl&gt;, c.5 &lt;lgl&gt;,</span></span>
<span class="co">#&gt; <span style="color: #949494;">#   c.6 &lt;lgl&gt;, c.7 &lt;lgl&gt;, c.8 &lt;lgl&gt;, c.9 &lt;lgl&gt;, c.10 &lt;lgl&gt;</span></span></code></pre></div>
<p>You can get help on any object in
<code>series.system.estimation.masked.data</code> using the built-in
help. For instance, to get information on the data set
<code>exp_series_data_1</code>, type <code><a href="../reference/exp_series_data_1.html">?exp_series_data_1</a></code> in
your R console.</p>
</div>
<div class="section level2">
<h2 id="statistical-model">Statistical model<a class="anchor" aria-label="anchor" href="#statistical-model"></a>
</h2>
<p>TODO: Cut-and-paste a lot of the material in statistical model
section and distribution derivation section into here, but only just
enough to be able to derive the log-likelihood. We will also need a few
key distribution functions and hazard functions for some of the other
material.</p>
<p>In this vignette, We consider two candidate set models, <span class="math inline">\(m_0\)</span> and <span class="math inline">\(m_1\)</span>.</p>
<div class="section level3">
<h3 id="candidate-model-m_0">Candidate model <span class="math inline">\(m_0\)</span><a class="anchor" aria-label="anchor" href="#candidate-model-m_0"></a>
</h3>
<p>In model <span class="math inline">\(m_0\)</span>, the <span class="math inline">\(j\)</span>-th observation in the masked data has a
candidate set <span class="math inline">\(C_j\)</span> that contains the
failed component, in addition to a random selection (without
replacement) of <span class="math inline">\(w_j-1\)</span> additional
components.</p>
</div>
<div class="section level3">
<h3 id="candidate-model-m_1-alpha-masked-candidates">Candidate model <span class="math inline">\(m_1\)</span>: <span class="math inline">\(\alpha\)</span>-masked candidates<a class="anchor" aria-label="anchor" href="#candidate-model-m_1-alpha-masked-candidates"></a>
</h3>
<p>In model <span class="math inline">\(m_1\)</span>, the <span class="math inline">\(j\)</span>-th observation in the masked data has a
candidate set <span class="math inline">\(C_j\)</span> described by the
following:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(C_j\)</span> contains the failed node
with probability <span class="math inline">\(\alpha_j\)</span>.
Additionally, it contains a random selection (without replacement) of
<span class="math inline">\(w_j-1\)</span> non-failed nodes.</p></li>
<li><p><span class="math inline">\(C_j\)</span> contains a random
selection (without replacement) of <span class="math inline">\(w_j\)</span> non-failed nodes with probability
<span class="math inline">\(1-\alpha_j\)</span>.</p></li>
</ol>
</div>
</div>
<div class="section level2">
<h2 id="exponential-series-system">Exponential series system<a class="anchor" aria-label="anchor" href="#exponential-series-system"></a>
</h2>
<p>The most straightforward series system to estimate is the series
system with exponentially distributed node lifetimes.</p>
<div class="section level3">
<h3 id="candidate-model-m_0-1">Candidate model <span class="math inline">\(m_0\)</span><a class="anchor" aria-label="anchor" href="#candidate-model-m_0-1"></a>
</h3>
<p>Suppose an exponential series system with <span class="math inline">\(m\)</span> nodes is parameterized by <span class="math inline">\(\theta = (3,4,5)'\)</span>. Then, the <span class="math inline">\(j\)</span>-th node has an exponentially
distributed lifetime with a failure rate <span class="math inline">\(\theta_j\)</span>.</p>
<p>In what follows, we consider the case of a series system with
exponentially distributed node lifetimes under candidate model <span class="math inline">\(m_0\)</span>, as described earlier. Later, we
consider model <span class="math inline">\(m_1\)</span>, the <span class="math inline">\(\alpha\)</span>-masked candidate model.</p>
<p>The candidate model <span class="math inline">\(m_0\)</span> for
masked data (of size <span class="math inline">\(n=1000\)</span>) for
this exponential series system, with <span class="math inline">\(w=2\)</span> candidates for each observation, is
given by:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">1000</span>
<span class="va">theta</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">4</span>,<span class="fl">5</span><span class="op">)</span>
<span class="va">m</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">theta</span><span class="op">)</span>
<span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">2</span>,<span class="va">n</span><span class="op">)</span>
<span class="co"># todo: rename to md_exp_series_data_m0</span>
<span class="va">md</span> <span class="op">&lt;-</span> <span class="fu">md_exp_series</span><span class="op">(</span><span class="va">n</span>,<span class="va">theta</span>,<span class="va">w</span>,<span class="va">md_candidate_m0</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">md</span>,pprint<span class="op">=</span><span class="cn">T</span>,drop_latent<span class="op">=</span><span class="cn">T</span><span class="op">)</span></code></pre></div>
<p>In the above, we used the function <code>md_exp_series</code>. To get
more help on it, type <code>?md_exp_series</code>.</p>
<div class="section level4">
<h4 id="log-likelihood-of-theta-given-masked-data">Log-likelihood of <span class="math inline">\(\theta\)</span> given
masked data<a class="anchor" aria-label="anchor" href="#log-likelihood-of-theta-given-masked-data"></a>
</h4>
<p>The log-likelihood function (technically, it is the log of the
likelihood kernel) is given by <span class="math display">\[
    L(\theta) =
    -\left(\sum_{i=1}^{n} s_i\right)\left(\sum_{j=1}^{m}\right) +
\sum_{i=1}^{n} \log\left(\sum_{k \in c_i} \lambda_k\right).
\]</span></p>
<p>The following log-likelihood constructor,
<code>md_loglike_exp_series_reg_cand</code>, is implemented using
minimally sufficient statistics, which significantly improves the
computational efficiency of computing the log-likelihood.</p>
<p>We compute the log-likelihood function as a function of the masked
data <code>md</code> with:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/md_loglike_exp_series_reg_cand.html">md_loglike_exp_series_reg_cand</a></span><span class="op">(</span><span class="va">md</span><span class="op">)</span></code></pre></div>
<p>The log-likelihood function contains the maximum amount of
information about parameter <span class="math inline">\(\theta\)</span>
given the sample of masked data <code>md</code>.</p>
<p>Suppose we do not know that <span class="math inline">\(\theta =
(3,4,5)'\)</span>. With the log-likelihood, we may estimate <span class="math inline">\(\theta\)</span> with <span class="math inline">\(\hat\theta\)</span> by solving <span class="math display">\[
    \hat\theta = \operatorname{argmax}_{\theta}
\operatorname{kloglik}(\theta),
\]</span> i.e., finding the point that <em>maximizes</em> the
log-likelihood on the observed sample <code>md</code>. This is known as
<em>maximum likelihood estimation</em>.</p>
<p>We typically solve for the MLE by solving <span class="math display">\[
    \nabla \operatorname{kloglik}(\theta) |_{\theta=\hat\theta} = 0.
\]</span></p>
<p>We use the iterative method known as the Fisher scoring algorithm to
solve this, <span class="math display">\[
    \theta^{(n+1)} = \theta^n + I^{-1}(\theta^n) \nabla
\operatorname{kloglik}(\theta^n),
\]</span> where <span class="math inline">\(I\)</span> is the
information matrix (or observed information matrix).</p>
<p>The function <code>md_mle_exp_series_m0</code> is a small wrapper for
this function, providing <code>md_fisher_scoring</code> with the
appropriate arguments. We find <span class="math inline">\(\hat\theta\)</span> by running the following R
code:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mle</span> <span class="op">&lt;-</span> <span class="fu">md_mle_exp_series_reg_cand</span><span class="op">(</span><span class="va">md</span><span class="op">)</span> 
<span class="va">theta.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">theta.hat</span>,digits<span class="op">=</span><span class="fl">3</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>The function <code>md_mle_exp_series_m0</code> returns an
<code>md_estimate</code> object, which has various methods implemented
for it, e.g., <code>confint</code> (computes the estimators confidence
interval). In the above, we see use of the <code>point</code> method,
which takes an estimator object and obtains its <em>best</em> point
estimate, or in this case, the MLE <span class="math inline">\(\hat\theta\)</span>.</p>
<p>We see that <span class="math inline">\(\hat\theta = (1, 1,
1)\)</span>.</p>
<p>If we let the third argument in the log-likelhood function be fixed
at <span class="math inline">\(\hat\theta_3 = 1\)</span>, then we may
profile the log-likelihood function over the first two parameters:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">prof</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta1</span><span class="op">)</span> <span class="op">{</span> <span class="fu">loglik</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">theta1</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">}</span>
<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">-</span><span class="fl">3</span>,<span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">+</span><span class="fl">3</span>,<span class="fl">.05</span><span class="op">)</span><span class="op">)</span>
<span class="va">data</span><span class="op">$</span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span>
    <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">prof</span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span><span class="op">)</span>
<span class="va">data</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>,<span class="fu">prof</span><span class="op">(</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Due to sampling variability, different runs of the experiment will
result in different outcomes, i.e., <span class="math inline">\(\hat\theta\)</span> has a sampling distribution.
We see that <span class="math inline">\(\hat\theta \neq \theta\)</span>,
but it is reasonably close. We may measure this sampling variability
using the variance-covariance matrix, bias, mean squared error (MSE),
and confidence intervals.</p>
</div>
<div class="section level4">
<h4 id="variance-covariance-matrix">Variance-covariance matrix<a class="anchor" aria-label="anchor" href="#variance-covariance-matrix"></a>
</h4>
<p>The estimator <span class="math inline">\(\hat\theta\)</span> as a
function of a random sample of masked data has a sampling
distribution.</p>
<div class="section level5">
<h5 id="information-matrix">Information matrix<a class="anchor" aria-label="anchor" href="#information-matrix"></a>
</h5>
<p>Theoretically, <span class="math inline">\(\hat\theta\)</span>
converges in distribution to the multivariate normal with a mean <span class="math inline">\(\theta\)</span> and a variance-covariance given
the the inverse of the observed Fisher matrix, <span class="math display">\[
    J(\theta) = -\nabla^2 \operatorname{loglik}(\theta).
\]</span> Since <span class="math inline">\(J\)</span> is a function of
a random sample, it is a random matrix.</p>
<p>However, when the nodes are exponentially distributed, we may take
the expectation <span class="math display">\[
    I(\theta) = -E(\nabla^2 \operatorname{loglik}(\theta)),
\]</span> and derive a closed-form solution.</p>
<p>The inverse of the information matrix <span class="math inline">\(I\)</span> (or <span class="math inline">\(J\)</span>) computes the variance-covariance
matrix. For <span class="math inline">\(3\)</span>-out-of-<span class="math inline">\(3\)</span> exponential series system, this results
in <span class="math display">\[
V(\theta) =
    \frac{\lambda_1+\lambda_2+\lambda_3}{n}
    \begin{pmatrix}
        \lambda_1+\lambda_2+\lambda_3 &amp;
-\lambda_3                    &amp; -\lambda_2\\
        -\lambda_3                    &amp;
\lambda_1+\lambda_2+\lambda_3 &amp; -\lambda_1\\
        -\lambda_2                    &amp;
-\lambda_1                    &amp; \lambda_1+\lambda_2+\lambda_3
    \end{pmatrix}.
\]</span></p>
<p>Asymptotically, <span class="math inline">\(\hat\theta\)</span> is
the UMVUE, i.e., it is unbiased and obtains the minimum sampling
variance. An estimate of the variance-covariance <span class="math inline">\(V\)</span> may be obtained with:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">V.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level5">
<h5 id="bootstrap-sample-mean-and-sample-variance-covariance">Bootstrap: sample mean and sample variance-covariance<a class="anchor" aria-label="anchor" href="#bootstrap-sample-mean-and-sample-variance-covariance"></a>
</h5>
<p>Another way we may estimate the variance-covariance matrix is with
parameter Bootstrapping.</p>
<p>Using the MLE <span class="math inline">\(\hat\theta\)</span>, we may
sample from the masked data model with:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">B</span> <span class="op">&lt;-</span> <span class="fl">200</span> <span class="co"># bootstrap replicates</span>
<span class="va">theta.hat.sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>nrow<span class="op">=</span><span class="va">B</span>,ncol<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span><span class="op">)</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">B</span><span class="op">)</span>
<span class="op">{</span>
    <span class="va">theta.hat.sim</span><span class="op">[</span><span class="va">i</span>,<span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html" class="external-link">as.vector</a></span><span class="op">(</span><span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="fu">md_mle_exp_series_m0</span><span class="op">(</span>
        <span class="fu">md_exp_series</span><span class="op">(</span>
            n<span class="op">=</span><span class="va">n</span>,
            theta<span class="op">=</span><span class="va">theta.hat</span>,
            w<span class="op">=</span><span class="va">w</span>,
            candidate_model<span class="op">=</span><span class="va">md_candidate_m0</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Now that we have Bootstrapped sample of MLEs, <span class="math inline">\(\hat\theta^{(1)},\ldots,\hat\theta^{(B)}\)</span>,
we can compute its sample covariance to estimate <span class="math inline">\(V\)</span>:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">V.bs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html" class="external-link">cov</a></span><span class="op">(</span><span class="va">theta.hat.sim</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>This estimate of the variance-covariance matrix is similar to the
inverse Fisher information matrix.</p>
</div>
</div>
<div class="section level4">
<h4 id="bias-mse-and-confidence-intervals">Bias, MSE, and confidence intervals<a class="anchor" aria-label="anchor" href="#bias-mse-and-confidence-intervals"></a>
</h4>
<p>We would like to measure the accuracy and precision of <span class="math inline">\(\hat\theta\)</span>. In statistical literature,
the bias <span class="math display">\[
    \operatorname{b}(\hat\theta) = E(\hat\theta) - \theta
\]</span> is a measure of accuracy and variance is a measure of
precision.</p>
<p>The mean squared error, denoted by <span class="math inline">\(\operatorname{MSE}\)</span>, is a measure of
estimator error that incorporates both the bias and the variance, <span class="math display">\[
    \operatorname{MSE}(\hat\theta) = \operatorname{trace}(V) +
\operatorname{b}^2(\hat\theta).
\]</span></p>
<p>Since <span class="math inline">\(\hat\theta\)</span> is
asymptotically unbiased and minimum variance, <span class="math display">\[
    \lim_{n \to \infty} \operatorname{MSE}(\hat\theta) =
\operatorname{trace}(V).
\]</span></p>
<p>Thus, for sufficiently large samples, <span class="math inline">\(\operatorname{MSE}(\hat\theta)\)</span> is
approximately given by the <code>trace</code> of the estimated
variance-covariance matrix:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">mse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="va">V.hat</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Mean squared error as a function of sample size <span class="math inline">\(n\)</span>:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Ns</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">100</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">exp_series_data_1</span><span class="op">)</span>, <span class="fl">100</span><span class="op">)</span>
<span class="va">mses.vcov</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span>length<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">Ns</span><span class="op">)</span><span class="op">)</span>
<span class="va">mses</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">numeric</a></span><span class="op">(</span>length<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">Ns</span><span class="op">)</span><span class="op">)</span>

<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">Ns</span><span class="op">)</span><span class="op">)</span>
<span class="op">{</span>
    <span class="va">mses.vcov</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="fu">md_mle_exp_series_m0</span><span class="op">(</span><span class="va">exp_series_data_1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">Ns</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
    <span class="va">mses</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="fu">md_mle_exp_series_m0</span><span class="op">(</span><span class="va">exp_series_data_1</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="va">Ns</span><span class="op">[</span><span class="va">i</span><span class="op">]</span>,<span class="op">]</span><span class="op">)</span><span class="op">)</span> <span class="op">-</span> <span class="va">theta</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>
<span class="op">}</span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>mse<span class="op">=</span><span class="va">mses</span>,mses.vcov<span class="op">=</span><span class="va">mses.vcov</span>,n<span class="op">=</span><span class="va">Ns</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">n</span>,y<span class="op">=</span><span class="va">mses</span>,color<span class="op">=</span><span class="st">"sample"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">n</span>,y<span class="op">=</span><span class="va">mses.vcov</span>,color<span class="op">=</span><span class="st">"theory"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html" class="external-link">scale_color_manual</a></span><span class="op">(</span>name<span class="op">=</span><span class="st">"Legend"</span>,values<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"sample"</span><span class="op">=</span><span class="st">"blue"</span>, <span class="st">"theory"</span><span class="op">=</span><span class="st">"red"</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>A primary statistic is the <em>confidence interval</em>. A <span class="math inline">\((1-\alpha)100\%\)</span> confidence interval for
<span class="math inline">\(\theta_j\)</span> may be estimated with
<span class="math inline">\(\hat\theta_j \pm z_{1-\alpha/2}
\sqrt{\hat{V}_{j j}}\)</span>. We provide a method for doing this
calculation:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<p>How does this compare to the confidence intervals given that all
candidate sets in the sample have size <span class="math inline">\(w=1\)</span>?</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html" class="external-link">confint</a></span><span class="op">(</span><span class="fu">md_mle_exp_series_m0</span><span class="op">(</span>
    <span class="fu">md_exp_series</span><span class="op">(</span>n<span class="op">=</span><span class="va">n</span>,
                  theta<span class="op">=</span><span class="va">theta</span>,
                  w<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="va">n</span><span class="op">)</span>,
                  candidate_model<span class="op">=</span><span class="va">md_candidate_m0</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>length<span class="op">=</span><span class="va">.</span><span class="op">[[</span><span class="fl">2</span><span class="op">]</span><span class="op">]</span><span class="op">-</span><span class="va">.</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<p>We see that the lengths of the confidence intervals are significantly
shorter.</p>
<p>If <em>no</em> information is provided about the node failure in a
series system with <span class="math inline">\(m\)</span> nodes (<span class="math inline">\(w_i=m\)</span> for <span class="math inline">\(i=1,\ldots,n\)</span>), then the <span class="math inline">\(m_0\)</span> estimator is inconsistent.</p>
</div>
<div class="section level4">
<h4 id="sampling-distribution-of-hattheta">Sampling distribution of <span class="math inline">\(\hat\theta\)</span><a class="anchor" aria-label="anchor" href="#sampling-distribution-of-hattheta"></a>
</h4>
<p>We know that <span class="math inline">\(\hat\theta \sim
\mathcal{N}(\theta,I^{-1}(\theta))\)</span>. We can estimate the
sampling distribution of <span class="math inline">\(\hat\theta\)</span>
with <span class="math inline">\(\mathcal{N}(\hat\theta,I^{-1}(\hat\theta))\)</span>.</p>
<p>This makes it trivial to estimate any other function of <span class="math inline">\(\theta\)</span> by sampling from the
approximation:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">samp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/sampler.html" class="external-link">sampler</a></span><span class="op">(</span><span class="fu"><a href="../reference/make_normal.html">make_normal</a></span><span class="op">(</span><span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span>,<span class="fu"><a href="https://rdrr.io/r/stats/vcov.html" class="external-link">vcov</a></span><span class="op">(</span><span class="va">mle</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">mles</span> <span class="op">&lt;-</span> <span class="fu">samp</span><span class="op">(</span>n<span class="op">=</span><span class="fl">1000</span><span class="op">)</span></code></pre></div>
<p>We show a contour plot of the first two components of each point in
the MLE sample with:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">mles</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span>,y<span class="op">=</span><span class="va">mles</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>,<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>,y<span class="op">=</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level4">
<h4 id="estimating-node-failures-from-a-sample">Estimating node failures from a sample<a class="anchor" aria-label="anchor" href="#estimating-node-failures-from-a-sample"></a>
</h4>
<p>Another characteristic we may wish to estimate is the probability
that a particular node in an observation caused the system failure.</p>
<p>We wish to use as much information as possible to do this estimation.
We consider three cases:</p>
<ol style="list-style-type: decimal">
<li><p>We have masked data <code>md</code> with candidate sets and
system failure times and seek to estimate the node failure probabilities
of observations in this data. This case provides the most accurate
estimates of the node probability failures, as have both system failure
times and candidate sets as predictors of the node failure.</p></li>
<li><p>We have a new observation of a system failure time and an
estimate of <span class="math inline">\(\theta\)</span> from
<code>md</code>. In this case, we cannot condition on candidate sets,
since the observation does not include that information. However, we do
have a system failure time.</p></li>
<li><p>We have an estimate of <span class="math inline">\(\theta\)</span> from <code>md</code> but wish to
predict the node failure of a system that has failed, but we do not know
when it failed.</p></li>
</ol>
<p>We consider case 1 describe above where we have masked data
<code>md</code> that includes both candidate sets and system failure
times.</p>
<p>In this case, we are interested in <span class="math display">\[
    f_{K|C,S}(k|c,s,\theta) = \frac{h_k(s)}{\sum_{j \in c} h_j(s)},
\]</span> which in the exponential series case simplifies to <span class="math display">\[
    f_{K|C,S}(k|c,s,\theta) = \frac{\lambda_k}{\sum_{j \in c}
\lambda_j}.
\]</span></p>
<p>We model this probability distribution with
<code>md_exp_series_node_failure_m0</code>. We also provide a decorator
function <code>md_series_node_failure_decorator_m0</code> that accepts
masked data as input and an <code>md_exp_series_node_failure_m0</code>
object and returns the masked data with columns for node failure
probabilities given by <code>k.1</code>,…,<code>k.m</code>.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fk</span> <span class="op">&lt;-</span> <span class="fu">md_exp_series_node_failure_m0</span><span class="op">(</span><span class="va">theta.hat</span><span class="op">)</span>
<span class="va">md</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"w"</span>,<span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html" class="external-link">starts_with</a></span><span class="op">(</span><span class="st">"t."</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu">md_series_node_failure_decorator_m0</span><span class="op">(</span><span class="va">fk</span><span class="op">)</span></code></pre></div>
<p>We notice that every row over the columns <code>k.1</code>,
<code>k.2</code>, and <code>k.3</code> given a specific candidate set
are the same. This is as expected, since in the case of the exponential
series, the node failure rates <span class="math inline">\(f_{K|C,S}\)</span> are not a function of system
failure time.</p>
<p>If we already had an estimate of <span class="math inline">\(\theta\)</span> and we sought to predict the
failed nodes from only system lifetime data, we would just let the
candidate sets contain all of the nodes.</p>
<p>Also, observe that the node failure probabilities <span class="math display">\[
    \hat{k}(\theta) = (\hat{k}_1,\hat{k}_2,\hat{k}_3)'
\]</span> is a random vector whose sampling distribution is a
multivariate normal <span class="math display">\[
    \hat{k}(\theta) \sim \mathcal{N}(k(\theta), V(k(\theta))).
\]</span></p>
<p>While these parameters could possibly be derived as functions of
<span class="math inline">\(\theta\)</span>, earlier we discussed how we
can simulate draws from <span class="math inline">\(\hat\theta\)</span>
and applying the statistic of interest.</p>
<p>For instance, once we have a simulated sample <span class="math inline">\(\hat{k}^{(1)},\ldots,\hat{k}^{(B)}\)</span>, we
can operate on this data to estimate desired characteristics like
confidence intervals for <span class="math inline">\(k(\theta)\)</span>.</p>
</div>
<div class="section level4">
<h4 id="estimating-system-lifetime-intervals-from-candidate-sets">Estimating system lifetime intervals from candidate sets<a class="anchor" aria-label="anchor" href="#estimating-system-lifetime-intervals-from-candidate-sets"></a>
</h4>
<p>Suppose we do not know the system failure time, but have masked data
with candidate sets and we have already estimated the parameters of the
series system.</p>
<p>Then, we can predict system failure times given these candidate sets.
Observe that <span class="math display">\[
    f_{S|C}(s|c,\theta) = f_{S,C}(c,s|\theta) / f_C(c)
\]</span> which simplifies to thinking about the series system as being
over the subset of nodes in <span class="math inline">\(c\)</span>.
Thus, <span class="math display">\[
    S|c = \min\{T_j | j \in c\}.
\]</span></p>
<p>We provide an estimate of the shortest interval that includes the
system failure time <span class="math inline">\(S|c\)</span> with, say,
<span class="math inline">\(90\%\)</span> probability. In the case of
the exponential series system, this is just <span class="math inline">\((0,F^{-1}_{S|c}(0.95))\)</span>.</p>
<p>We consider a larger and more complicated data set for this next
example, <code>exp_series_data_3</code>. Type
<code><a href="../reference/exp_series_data_3.html">?exp_series_data_3</a></code> to learn more about it. It has a true
parameter value of <span class="math inline">\(\theta =
(3,5,4,6,7,2,8,9,10,11)'\)</span>. We decorate its masked data with
these upper and lower bounds and compare the result with the known
system lifetimes, column <code>s</code>:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="op">(</span><span class="va">theta.large.hat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://queelius.github.io/algebraic.mle/reference/point.html" class="external-link">point</a></span><span class="op">(</span><span class="fu">md_mle_exp_series_m0</span><span class="op">(</span><span class="va">exp_series_data_3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="va">q.hat</span> <span class="op">&lt;-</span> <span class="fu">md_exp_series_system_failure_interval_m0</span><span class="op">(</span><span class="va">theta.large.hat</span>,<span class="fl">.85</span><span class="op">)</span>
<span class="op">(</span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">exp_series_data_3</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span> <span class="fu">md_series_system_failure_decorator_m0</span><span class="op">(</span><span class="va">q.hat</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"w"</span>,<span class="st">"k"</span>,<span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html" class="external-link">starts_with</a></span><span class="op">(</span><span class="st">"t."</span><span class="op">)</span>,<span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html" class="external-link">starts_with</a></span><span class="op">(</span><span class="st">"c."</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html" class="external-link">%&gt;%</a></span>
    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>contains <span class="op">=</span> <span class="va">s</span> <span class="op">&gt;=</span> <span class="va">s.lower</span> <span class="op">&amp;&amp;</span> <span class="va">s</span> <span class="op">&lt;=</span> <span class="va">s.upper</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>We can compute the proportion that contain the system lifetime
with:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">contains</span><span class="op">)</span>
<span class="co">#&gt; [1] 0.952</span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="relaxing-conditions">Relaxing conditions<a class="anchor" aria-label="anchor" href="#relaxing-conditions"></a>
</h3>
<p>In real-world data sets, the conditions we assume may not be entirely
realistic. We may relax these conditions in order to see how well the
MLE <span class="math inline">\(\hat{\theta}\)</span> performs under
these ostensibly more realistic and more relaxed conditions.</p>
<p>The most important condition, <span class="math inline">\(\Pr\{K_i =
j|T_i=t_i\} = 1\)</span>, may be too stringent. Instead, we can relax it
by assuming only that <span class="math inline">\(\Pr\{K_i = j|T_i=t_i\}
= \alpha\)</span> for some <span class="math inline">\(\alpha\)</span>
in <span class="math inline">\((0,1)\)</span>.</p>
<p>The masking probability condition, <span class="math display">\[
\Pr\{C_i = c_i | K_i = j, T_i=t_i\} = \Pr\{C_i = c_i | K_i = j',
T_i=t_i\}
\]</span> for any <span class="math inline">\(j'\)</span> in <span class="math inline">\(c_i\)</span> may also be relaxed by replacing the
equality with a distance measure, such as <span class="math display">\[
\max_{j,k} \mid \Pr\{C_i = c_i | K_i = j, T_i=t_i\} -
    \Pr\{C_i = c_i | K_i = k, T_i=t_i\} \mid \leq \gamma
\]</span> for any <span class="math inline">\(i,j\)</span> in <span class="math inline">\(c_i\)</span>.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Alexander Towell.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
